36. What's In An Image (and What Isn't)
Image
- app binaries and dependencies
- metadata about the image data and how to run the image
- official: "An image is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime"
- not a complete OS -- no kernel, no kernel modules (e.g. drivers)
- as small as one file, or as big as an Ubuntu distro with apt, Apache, PHP and more installed


37. The Mighty Hub: Using Docker Hub Registry Images
Docker Hub: https://hub.docker.com/
- rare to want your software to update automatically; instead, you usually want to control that process with some other DevOps tool
- vet an image by:
-- looking at number of pulls and number of stars
-- looking at an open source repository that shows how the image was made
[[Resources]]
List of Official Docker Images:
https://github.com/docker-library/official-images/tree/master/library


38. Images and Their Layers: Discover the Image Cache
[docker image ls]
[docker history nginx:latest]
- every image starts with a blank layer known as [scratch]
- every set of changes on the file system in the image is another [layer]
- every layer gets its own unique [sha] to allow system to confirm that layer is different from another layer, storing each layer only once on a host
[Copy-on-Write] when container changes a layer on the image; copies file out into container's differencing for storage in container layer
[docker image inspect nginx] gives you [metadata] for an image

[[Resources]]
*About storage drivers*
https://docs.docker.com/storage/storagedriver/
- "Containers that write a lot of data consume more space than containers that do not. This is because most write operations consume new space in the container’s thin writable top layer.

Note: for write-heavy applications, you should not store the data in the container. Instead, use Docker volumes, which are independent of the running container and are designed to be efficient for I/O. In addition, volumes can be shared among containers and do not increase the size of your container’s writable layer."


39. Image Tagging and Pushing to Docker Hub
## Tagging
- Tag vs "Repository" as username or organization slash repository
- only official images get to be called just the repository name -- i.e. no username or organization designation
- tags are a little bit like [Git tags] an a little like [versions]
- a pointer to a specific image commit or really anything in that repository
- descriptions of images usually show [MULTIPLE Tags] (shown as both numbers and names) in each bullet for the [SAME Image ID]
- can [re-tag] existing Docker images
[docker image tag OriginalName[:TAG] NewName[:TAG]]
[docker image tag nginx bretfisher/nginx]
[docker image push bretfish/nginx] pushes/uploads changed layers to an image registry (default: Docker Hub)
- likely will be denied because [docker login] first required
- [docker login] without URL defaults to logging in to Docker Hub; can override by adding a server URL
-- used to store in config.json [cat .docker/config.json] file but now Docker for Mac stores the auth in Keychain for that user for better security
-- can [docker logout] if done or can't trust machine
- can push to a private repository, but best to make it private as of first creation


40. Building Images: The Dockerfile Basics
[Dockerfile] - recipe for creating your image
[cd dockerfile-sample-1/]
[code Dockerfile]
[docker build -f some-dockerfile] uses [-f] or [--file] to specify a different file from the default [Dockerfile]

[FROM] required, usually a minimal distribution, then use their package distribution systems to install what you need in your package

[ENV] stanza for environement variables settings, as the main way to set keys and values for container building and running containers
- each [stanza] is a [layer] in our docker [image], so order matters (top down)

[RUN] commands execute shell commands inside the container as it's building it (e.g. installing software with a package distribution system, or unzipping, or file editing inside container, or running shell scripts copied in earlier in the file, or any commands you can access inside the container at that point in time in the file
- proper way to do [logging] inside a container is to NOT log to a log file
- there's no [syslogd] or any other [syslog service] inside a container
- Docker handles all logging for us
- all we have to do is make sure everything we want captured is spit out to stdout and stderr
[RUN ln -sf /dev/stdout /var/log/nginx/access.log \
&& ln -sf /dev/stderr /var/log/nginx/error.log]

[EXPOSE] since by default NO TCP nor UDP ports are open inside a container
- does not expose anything from the container to a virtual network unless we list it in EXPOSE
- expose both ports 80 and 443 by [EXPOSE 80 443]
- does NOT mean these ports are opened automatically on our host; [-p] or [--publish] is used for that

[CMD] required parameter that is the final command that will be run every time you launch a new container from the image or every time you restart a stopped container


[[Resources]]
https://docs.docker.com/engine/reference/builder/


41. Building Images: Running Docker Builds
- Running Dockerfile from previous lesson:
[docker image build -t my-custom-nginx-jv .] dot means build it in this directory
- see hashes of build tags, where the next time you build from this dockerfile, if the line has not been changed in the dockerfile it is not going to re-run it; allows for shorter build times thereafter

- Now add an additional exposed port to [/Proj/study/udemy/udemy-docker-mastery/dockerfile-sample-1/Dockerfile]
- change stanza to: [EXPOSE 80 443 8080]
- now rebuild with: [docker image build -t my-custom-nginx-jv .]
- upon reaching the modified stanza line, EVERY line after that ALSO has to be [rebuilt] hence choosing carefully about what you put at the top portions of the Dockerfile to minimize the number of layers that require rebuilding below it


42. Building Images: Extending Official Images
- open /Proj/study/udemy/udemy-docker-mastery/dockerfile-sample-2/Dockerfile
- might want to add software, change the way it starts, add scripts to tweak configuration
- if official image isn't sufficient, might first look at Docker Hub for another popular tweaks of that image that might solve your problem OR just build your own (but it's more work and upkeep over time)

- [WORKDIR] is just a cd directory change [WORKDIR /usr/share/nginx/html] instead of doing a [RUN cd /usr/share/nginx/html] but using [WORKDIR] is a best practice whenever you're changing directories
- in this case we are moving to the default Nginx directory for its html files
- in default configuration on Docker Hub, nginx is just acting as a web server serving static files right off the container disk

- [COPY] is to copy your source code from your LOCAL machine or BUILD SERVERS into your container images
- here we overwrite the file in the nginx default directory so it uses our own custom homepage instead

- [CMD] REQUIRED stanza is missing, because there's already a CMD specified in the FROM image; we inherit everying from the Dockerfile where we're FROM'ing from; example of CHAINING Dockerfiles together so that images depend on other images, depend on other images, ...

[BEFORE AND AFTER]
**BEFORE**
- Standard nginx image behavior:
[docker container run --rm --publish 80:80 --detach --name my-og-nginx nginx]
- open it in browser: [open http://localhost -a "Brave Browser.app"]

**AFTER**
- Now with nginx using our index.html:
[docker image build -t my-custom-nginx .]
[docker container run --rm --publish 81:80 --detach --name my-own-nginx my-custom-nginx]
- open it in browser: [open http://localhost:81 -a "Brave Browser.app"]

[docker image ls] to see it at top as [my-custom-nginx          latest              51c577528f48        4 minutes ago       127MB]

- now tag it to ready it for publishing to Docker Hub
[docker image tag my-custom-nginx:latest jimmyvales/my-custom-nginx:latest]

- now push:
[docker push jimmyvales/my-custom-nginx]


Quiz 4: Image Quiz
[-f] is [--file] to use a file other than the default [Dockerfile]


43. Assignment: Build Your Own Dockerfile and Run Containers From It
- Make Dockerfile for Node.js app per instructions in [/Proj/study/udemy/udemy-docker-mastery/dockerfile-assignment-1/Dockerfile]
- Use Alpine version of official "node" 6.x image
- Goal: be able to open http://localhost

** MY STEPS **
[cd /Proj/study/udemy/udemy-docker-mastery/dockerfile-assignment-1]
modified [Dockerfile] as follows:

++++++++++++++++
# Instructions from the app developer
# - you should use the 'node' official image, with the alpine 6.x branch
FROM node:6-alpine

# - this app listens on port 3000, but the container should launch on port 80
#  so it will respond to http://localhost:80 on your computer
EXPOSE 3000

# - then it should use alpine package manager to install tini: 'apk add --update tini'
# - then it should create directory /usr/src/app for app files with 'mkdir -p /usr/src/app'
RUN apk add --update tini
RUN mkdir -p /usr/src/app

WORKDIR /usr/src/app

# - Node uses a "package manager", so it needs to copy in package.json file
COPY package.json package.json

# - then it needs to run 'npm install' to install dependencies from that file
RUN npm install && npm cache clean --force
# && creates a dependency on prior command being successful

# - to keep it clean and small, run 'npm cache clean --force' after above
# RUN npm cache clean --force

# - then it needs to copy in all files from current directory
COPY . .

# - then it needs to start container with command '/sbin/tini -- node ./bin/www'
CMD [ "/sbin/tini", "--", "node", "./bin/www"] 

# - in the end you should be using FROM, RUN, WORKDIR, COPY, EXPOSE, and CMD commands

# Bonus Extra Credit
# this will not have you setting up a complete image useful for local development, test, and prod
# it's just meant to get you started with basic Dockerfile concepts and not focus too much on
# proper Node.js use in a container. **If you happen to be a Node.js Developer**, then 
# after you get through more of this course, you should come back and use my 
# Node Docker Good Defaults sample project on GitHub to change this Dockerfile for 
# better local development with more advanced topics
# https://github.com/BretFisher/node-docker-good-defaults

++++++++++++++++

[docker image build -t assignment-1-node .]
[docker container run --rm --name jv-asgn-1 --detach --publish 80:3000 assignment-1-node]

44. Assignment Answers: Build Your Own Dockerfile and Run Containers From It
- fixed syntax above; otherwise all steps were right


45. Using Prune to Keep Your Docker System Clean (YouTube)
You can use "prune" commands to clean up images, volumes, build cache, and containers. Examples include:

- [docker image prune] to clean up just "dangling" images

- [docker system prune] will clean up everything

- The big one is usually [docker image prune -a] which will remove all images you're not using. Use [docker system df] to see space usage.

Remember each one of those commands has options you can learn with --help.

Here's a YouTube video I made about it: https://youtu.be/_4QzP7uwtvI

Lastly, realize that if you're using Docker Toolbox, the Linux VM won't auto-shrink. You'll need to delete it and re-create (make sure anything in docker containers or volumes are backed up). You can recreate the toolbox default VM with docker-machine rm default and then docker-machine create
